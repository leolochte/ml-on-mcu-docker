{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nntool.api import NNGraph\n",
    "from nntool.api.utils import RandomIter\n",
    "from nntool.api.utils import model_settings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network and prepare it for nntool\n",
    "\n",
    "Tensorflow already collects the neccesary statistics needed during [post training static quantization](https://huggingface.co/docs/optimum/concept_guides/quantization). We can import them into nntool using `load_quantization=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = NNGraph.load_graph(\"model.tflite\", load_quantization=True)\n",
    "G.adjust_order()\n",
    "G.fusions(\"scaled_match_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.quantize(\n",
    "    graph_options={\n",
    "            \"scheme\": \"SQ8\",  # Specify the quantization. You can choose betwen \"float\" and \"SQ8\"\n",
    "            \"use_ne16\": True    # Specify if we want to use the NE16 accelerator\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the memory consumption of each layer can give a good indication on how to improve the model. Notice the difference between the quantization schemes. Make sure to use `SQ8` when deploying to gvsoc or GAP9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.plot_mem_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to gvsoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.load('sample.npy')\n",
    "test_label = np.load('label.npy')\n",
    "labels = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
    "print(\"The loaded sample has label:\", test_label.item(), \"which corresponds to:\", labels[test_label.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = G.execute_on_target(\n",
    "    directory=\"kws_test_deploy_gap\",\n",
    "    input_tensors=[test_input],\n",
    "    at_loglevel=0,\n",
    "    at_log=True,\n",
    "    print_output=True,\n",
    "    settings=model_settings(\n",
    "        tensor_directory=\"tensors\",\n",
    "        model_directory=\"model_dir\",\n",
    "        l1_size=128000,\n",
    "        l2_size=1000000,\n",
    "        graph_const_exec_from_flash=True\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
